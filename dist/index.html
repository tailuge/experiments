<!DOCTYPE html>
<html>
<head>
    <title>Minimal TF.js Transformer</title>
    <!-- Use the latest stable version of TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
</head>
<body>
    <h3>Training Data (per line):</h3>
    <textarea id="trainingData" rows="5" cols="40">
This is good
That was bad
Amazing result
Terrible outcome
Great success
    </textarea><br>
    
    <input type="number" id="epochs" value="5" min="1" max="20" style="width: 50px;">
    <button onclick="trainModel()">Train Model</button>
    
    <h3>Inference:</h3>
    <input type="text" id="inputText" value="Awesome news">
    <button onclick="runInference()">Test</button>
    <div id="result"></div>
    <div id="trainingStatus"></div>

    <script>
        let model;
        const SEQ_LENGTH = 10;
        const VOCAB_SIZE = 128; // ASCII

        function createModel() {
            const model = tf.sequential();

            // Embedding layer
            model.add(tf.layers.embedding({
                inputDim: VOCAB_SIZE,
                outputDim: 8,
                inputLength: SEQ_LENGTH
            }));

            // Simple LSTM layer instead of MultiHeadAttention
            model.add(tf.layers.lstm({ units: 8 }));

            // Output layer
            model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));

            return model;
        }

        function preprocess(text) {
            const padded = text.slice(0, SEQ_LENGTH).padEnd(SEQ_LENGTH, ' ');
            return Array.from(padded).map(c => c.charCodeAt(0) % VOCAB_SIZE);
        }

        function generateLabels(texts) {
            // Simple synthetic task: detect if text contains 'a'
            return texts.map(text => text.toLowerCase().includes('a') ? 1 : 0);
        }

        async function trainModel() {
            if (!model) {
                model = createModel();
                model.compile({
                    optimizer: tf.train.adam(0.001),
                    loss: 'binaryCrossentropy',
                    metrics: ['accuracy']
                });
            }

            const trainingText = document.getElementById('trainingData').value.split('\n');
            const epochs = parseInt(document.getElementById('epochs').value);
            
            // Convert training data to tensors
            const inputs = trainingText.map(preprocess);
            const labels = generateLabels(trainingText);
            
            const inputTensor = tf.tensor2d(inputs, [inputs.length, SEQ_LENGTH]);
            const labelTensor = tf.tensor2d(labels, [labels.length, 1]);

            // Train the model
            for(let epoch = 1; epoch <= epochs; epoch++) {
                const history = await model.fit(inputTensor, labelTensor, {
                    epochs: 1,
                    shuffle: true,
                    verbose: 0
                });
                
                document.getElementById('trainingStatus').innerHTML += 
                    `Epoch ${epoch}: Loss ${history.history.loss[0].toFixed(4)}<br>`;
                
                await tf.nextFrame(); // Allow UI updates
            }

            inputTensor.dispose();
            labelTensor.dispose();
        }

        async function runInference() {
            if (!model) return;
            
            const text = document.getElementById('inputText').value;
            const input = tf.tensor2d([preprocess(text)]);
            const prediction = model.predict(input);
            const score = (await prediction.data())[0];
            
            document.getElementById('result').innerHTML = 
                `Prediction: ${score.toFixed(4)} (${score > 0.5 ? 'Positive' : 'Negative'})`;
            
            input.dispose();
            prediction.dispose();
        }
    </script>
</body>
</html>