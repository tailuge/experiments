<!doctype html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>Minimal TF.js Next-Token Predictor with Loss Chart</title>
    <!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <!-- Load Chart.js for loss graphing -->
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  </head>
  <body>
    <h3>Training Data (one sample per line):</h3>
    <textarea id="trainingData" rows="5" cols="80">
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
abcdefghijklmnopqrstuvwxyz
1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyztABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz.
    </textarea>
    <br />

    <label for="epochs">Epochs:</label>
    <input type="number" id="epochs" value="5" min="1" max="50" style="width: 50px">
    <button onclick="trainModel()">Train Model</button>

    <h3>Inference:</h3>
    <input type="text" id="inputText" value="abc">
    <button onclick="runInference()">Test</button>
    <div id="result" style="margin-top: 10px; font-weight: bold;"></div>

    <h3>Training Status:</h3>
    <pre id="trainingStatus" style="background: #f0f0f0; padding: 5px;"></pre>

    <h3>Training Loss Graph:</h3>
    <canvas id="lossChart" width="600" height="150"></canvas>

    <script>
      // --- Global Constants & Variables ---
      const SEQ_LENGTH = 32;      // Context window of 64 characters
      const VOCAB_SIZE = 128;     // ASCII: characters 0â€“127

      let model;
      let globalEpochCounter = 0; // Total epochs trained across sessions.
      let lossChart = null;       // Will hold our Chart.js chart instance.

      // --- Initialize Chart.js Loss Graph ---
      function initializeLossChart() {
        const ctx = document.getElementById('lossChart').getContext('2d');
        lossChart = new Chart(ctx, {
          type: 'line',
          data: {
            labels: [],
            datasets: [{
              label: 'Training Loss',
              data: [],
              borderColor: 'rgba(0,122,204,1)',
              fill: false,
              tension: 0.1
            }]
          },
          options: {
            scales: {
              x: {
                title: { display: true, text: 'Epoch' }
              },
              y: {
                title: { display: true, text: 'Loss' }
              }
            }
          }
        });
      }

      // Initialize the loss graph when the page loads.
      window.onload = function() {
        initializeLossChart();
      };

      // --- Model Definition ---
      function createModel() {
        logWithTime("create model")
        const model = tf.sequential();
        model.add(tf.layers.embedding({
          inputDim: VOCAB_SIZE,
          outputDim: 8,
          inputLength: SEQ_LENGTH
        }));
        model.add(tf.layers.lstm({ units: 4 }));
        model.add(tf.layers.dense({
          units: VOCAB_SIZE,
          activation: "softmax"  // Predicts a probability distribution over ASCII tokens.
        }));
        logWithTime("Model created")
        return model;
      }

      // --- Data Preparation ---
      // For each training sample (one per line), slide a window of SEQ_LENGTH and use the following character as the target.
      function prepareData() {
        logWithTime("prepare data")
        const rawData = document.getElementById('trainingData').value
                          .split('\n')
                          .map(line => line.trim())
                          .filter(line => line.length > 0);
        const inputs = [];
        const labels = [];
        rawData.forEach(line => {
          // Pad the line on the right so it has at least SEQ_LENGTH+1 characters.
          let padded = line.padEnd(SEQ_LENGTH + 1, ' ');
          // Generate as many (input, target) pairs as possible.
          for (let i = 0; i <= padded.length - (SEQ_LENGTH + 1); i++) {
            const inputSeq = padded.slice(i, i + SEQ_LENGTH);
            const labelChar = padded[i + SEQ_LENGTH];
            inputs.push(inputSeq);
            labels.push(labelChar);
          }
        });

        // Convert each character to its ASCII code.
        const xsBuffer = inputs.map(seq => seq.split('').map(ch => ch.charCodeAt(0)));
        const ysBuffer = labels.map(ch => ch.charCodeAt(0));

        // xs is used for the embedding layer (int32 is fine).
        const xs = tf.tensor2d(xsBuffer, [xsBuffer.length, SEQ_LENGTH], 'int32');
        // Convert labels to float32 to avoid type errors.
        const ys = tf.tensor1d(ysBuffer, 'int32').toFloat();
        logWithTime("data prepared")
        return { xs, ys };
      }

      // --- Update Loss Chart ---
      function updateLossChart(epoch, loss) {
        lossChart.data.labels.push(epoch);
        lossChart.data.datasets[0].data.push(loss);
        lossChart.update();
      }

      // --- Training Function ---
      async function trainModel() {
        // Clear previous training status (text) but preserve the loss chart.
        document.getElementById('trainingStatus').textContent = '';
        const { xs, ys } = prepareData();

        model = createModel();
        logWithTime("compile model")

        model.compile({
          optimizer: tf.train.adam(),
          loss: 'sparseCategoricalCrossentropy'
        });

        logWithTime("fit")

        const epochs = parseInt(document.getElementById('epochs').value, 10);
        await model.fit(xs, ys, {
          epochs: epochs,
          callbacks: {
            onEpochEnd: async (epoch, logs) => {
              globalEpochCounter++;
              document.getElementById('trainingStatus').textContent = 
                `Epoch ${globalEpochCounter}: loss = ${logs.loss.toFixed(4)}\n`;
              updateLossChart(globalEpochCounter, logs.loss);
              await tf.nextFrame(); // Allow the UI to update.
            }
          }
        });
        xs.dispose();
        ys.dispose();
      }

      // --- Inference Function ---
      // This function accepts any input string (even if shorter than SEQ_LENGTH),
      // pads it to SEQ_LENGTH, and then autoregressively predicts 10 next tokens.
      async function runInference() {
        if (!model) {
          alert("Please train the model first!");
          return;
        }
        let prompt = document.getElementById('inputText').value;
        let generated = prompt;
        // Ensure the initial inputSequence is exactly SEQ_LENGTH characters.
        let inputSequence = prompt.padStart(SEQ_LENGTH, ' ').slice(-SEQ_LENGTH);

        // Autoregressively generate 10 tokens.
        for (let i = 0; i < 10; i++) {
          // Always pad the sequence (in case generated is shorter than SEQ_LENGTH).
          inputSequence = inputSequence.padStart(SEQ_LENGTH, ' ');
          const inputCodes = inputSequence.split('').map(ch => ch.charCodeAt(0));
          const inputTensor = tf.tensor2d([inputCodes], [1, SEQ_LENGTH], 'int32');
          const prediction = model.predict(inputTensor);
          const predictedIndex = (await prediction.argMax(-1).data())[0];
          const predictedChar = String.fromCharCode(predictedIndex);
          generated += predictedChar;
          // Update inputSequence to be the last SEQ_LENGTH characters of generated.
          inputSequence = generated.slice(-SEQ_LENGTH).padStart(SEQ_LENGTH, ' ');
          inputTensor.dispose();
          prediction.dispose();
        }
        document.getElementById('result').textContent = generated;
      }

      function logWithTime(message) {
  const now = new Date();
  const seconds = now.getSeconds().toString().padStart(2, '0'); // Pad with leading zero if needed
  const milliseconds = now.getMilliseconds().toString().padStart(3, '0'); //Pad with leading zero if needed
  console.log(`[${seconds}.${milliseconds}] ${message}`);
}
    </script>
  </body>
</html>
